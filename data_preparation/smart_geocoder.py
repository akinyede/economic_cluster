#!/usr/bin/env python3
"""Smart geocoding for 525K+ businesses with efficient batching and caching"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import json
import time
from pathlib import Path
import hashlib

logger = logging.getLogger(__name__)

@dataclass
class GeoLocation:
    lat: float
    lon: float
    source: str  # 'centroid', 'precise', 'county'
    confidence: float

class SmartGeocoder:
    """Efficient geocoding for large business datasets with intelligent precision allocation"""
    
    def __init__(self, cache_dir: str = 'cache/geocode'):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # County and city centroids for Kansas City MSA
        self.county_centroids = {
            'Jackson County': (39.0166, -94.3633),
            'Clay County': (39.3078, -94.4195),
            'Platte County': (39.3703, -94.7747),
            'Cass County': (38.6453, -94.3505),
            'Johnson County': (38.8814, -94.8191),
            'Wyandotte County': (39.1178, -94.7453),
            'Miami County': (38.5667, -94.8447),
            'Leavenworth County': (39.2692, -94.9247),
            'Franklin County': (38.5833, -95.2667),
        }
        
        self.city_centroids = {
            'Kansas City': (39.0997, -94.5786),
            'Overland Park': (38.9822, -94.6708),
            'Kansas City, KS': (39.1142, -94.6275),
            'Olathe': (38.8814, -94.8191),
            'Independence': (39.0911, -94.4155),
            'Lee\'s Summit': (38.9108, -94.3822),
            'Shawnee': (39.0228, -94.7151),
            'Blue Springs': (39.0169, -94.2816),
            'Lenexa': (38.9536, -94.7336),
            'Leavenworth': (39.3111, -94.9225),
            'Liberty': (39.2461, -94.4191),
            'Raytown': (39.0086, -94.4636),
            'Gladstone': (39.2039, -94.5544),
            'Prairie Village': (38.9917, -94.6336),
            'Grandview': (38.8858, -94.5331),
        }
        
        self.precise_quota = 1000  # Max businesses for precise geocoding
        self.used_precise = 0
        self.geocode_cache = {}
        self._load_cache()
    
    def geocode_businesses(self, df: pd.DataFrame, batch_size: int = 100) -> pd.DataFrame:
        """
        Geocode businesses using smart strategy:
        1. Use city centroids for most businesses
        2. Precise geocoding for KC city businesses (limit 1000)
        3. County centroids as fallback
        """
        logger.info(f"Starting smart geocoding for {len(df)} businesses")
        
        # Add geocoding columns
        if 'latitude' not in df.columns:
            df['latitude'] = None
        if 'longitude' not in df.columns:
            df['longitude'] = None
        if 'geo_source' not in df.columns:
            df['geo_source'] = None
        if 'geo_confidence' not in df.columns:
            df['geo_confidence'] = 0.0

        # Pass through existing lat/lon if present
        try:
            if 'lat' in df.columns and 'lon' in df.columns:
                lat = pd.to_numeric(df['lat'], errors='coerce')
                lon = pd.to_numeric(df['lon'], errors='coerce')
                use = lat.notna() & lon.notna() & df['geo_source'].isna()
                if use.any():
                    df.loc[use, 'latitude'] = lat[use]
                    df.loc[use, 'longitude'] = lon[use]
                    df.loc[use, 'geo_source'] = 'existing'
                    df.loc[use, 'geo_confidence'] = 0.9
        except Exception:
            pass
        
        # Strategy 1: City centroids for businesses with known cities
        city_matches = 0
        for city, (lat, lon) in self.city_centroids.items():
            mask = df['city'].str.contains(city, case=False, na=False) & df['geo_source'].isna()
            if mask.sum() > 0:
                df.loc[mask, 'latitude'] = lat
                df.loc[mask, 'longitude'] = lon
                df.loc[mask, 'geo_source'] = 'city_centroid'
                df.loc[mask, 'geo_confidence'] = 0.7
                city_matches += mask.sum()
        
        logger.info(f"  Geocoded {city_matches} businesses using city centroids")
        
        # Strategy 2: Precise geocoding for select KC businesses
        kc_mask = (df['city'].str.contains('Kansas City', case=False, na=False)) & \
                  (df['geo_source'].isna()) & \
                  (df['revenue_estimate'] > df['revenue_estimate'].quantile(0.8))
        
        kc_businesses = df[kc_mask].head(self.precise_quota - self.used_precise)
        
        if len(kc_businesses) > 0:
            logger.info(f"  Attempting precise geocoding for {len(kc_businesses)} high-value KC businesses")
            precise_results = self._precise_geocode_batch(kc_businesses)
            
            for idx, geo in precise_results.items():
                df.loc[idx, 'latitude'] = geo.lat
                df.loc[idx, 'longitude'] = geo.lon
                df.loc[idx, 'geo_source'] = geo.source
                df.loc[idx, 'geo_confidence'] = geo.confidence
                self.used_precise += 1
        
        # Strategy 3: County centroids as fallback
        county_matches = 0
        for county, (lat, lon) in self.county_centroids.items():
            mask = (df['county'].str.contains(county.split()[0], case=False, na=False)) & \
                   (df['geo_source'].isna())
            if mask.sum() > 0:
                df.loc[mask, 'latitude'] = lat
                df.loc[mask, 'longitude'] = lon
                df.loc[mask, 'geo_source'] = 'county_centroid'
                df.loc[mask, 'geo_confidence'] = 0.5
                county_matches += mask.sum()
        
        logger.info(f"  Geocoded {county_matches} businesses using county centroids")
        
        # Final fallback: KC metro center
        remaining = df['geo_source'].isna()
        if remaining.sum() > 0:
            df.loc[remaining, 'latitude'] = 39.0997
            df.loc[remaining, 'longitude'] = -94.5786
            df.loc[remaining, 'geo_source'] = 'metro_default'
            df.loc[remaining, 'geo_confidence'] = 0.3
            logger.info(f"  Used metro center for {remaining.sum()} remaining businesses")
        
        # Save cache
        self._save_cache()
        
        # Summary statistics
        logger.info("\nGeocoding Summary:")
        logger.info(f"  Total businesses: {len(df)}")
        logger.info(f"  Precise geocoding: {(df['geo_source'] == 'precise').sum()}")
        logger.info(f"  City centroids: {(df['geo_source'] == 'city_centroid').sum()}")
        logger.info(f"  County centroids: {(df['geo_source'] == 'county_centroid').sum()}")
        logger.info(f"  Metro default: {(df['geo_source'] == 'metro_default').sum()}")
        logger.info(f"  Average confidence: {df['geo_confidence'].mean():.2f}")
        
        return df
    
    def _precise_geocode_batch(self, businesses: pd.DataFrame) -> Dict[int, GeoLocation]:
        """
        Simulate precise geocoding with realistic variance around city centers
        In production, this would call a real geocoding API
        """
        results = {}
        
        for idx, row in businesses.iterrows():
            # Generate cache key
            address_key = f"{row.get('address', '')}_{row.get('city', '')}_{row.get('state', '')}"
            cache_key = hashlib.md5(address_key.encode()).hexdigest()
            
            # Check cache
            if cache_key in self.geocode_cache:
                results[idx] = self.geocode_cache[cache_key]
                continue
            
            # Simulate API call with realistic variance
            base_lat, base_lon = self.city_centroids.get('Kansas City', (39.0997, -94.5786))
            
            # Add realistic variance (approximately 10 mile radius)
            lat_variance = np.random.normal(0, 0.05)
            lon_variance = np.random.normal(0, 0.05)
            
            geo = GeoLocation(
                lat=base_lat + lat_variance,
                lon=base_lon + lon_variance,
                source='precise',
                confidence=0.95
            )
            
            self.geocode_cache[cache_key] = geo
            results[idx] = geo
            
            # Simulate API rate limiting
            time.sleep(0.01)
        
        return results
    
    def _load_cache(self):
        """Load geocoding cache from disk"""
        cache_file = self.cache_dir / 'geocode_cache.json'
        if cache_file.exists():
            try:
                with open(cache_file, 'r') as f:
                    raw_cache = json.load(f)
                    # Reconstruct GeoLocation objects
                    for key, data in raw_cache.items():
                        self.geocode_cache[key] = GeoLocation(**data)
                logger.info(f"Loaded {len(self.geocode_cache)} cached geocode results")
            except Exception as e:
                logger.warning(f"Could not load geocode cache: {e}")
    
    def _save_cache(self):
        """Save geocoding cache to disk"""
        cache_file = self.cache_dir / 'geocode_cache.json'
        try:
            # Convert GeoLocation objects to dicts
            serializable_cache = {}
            for key, geo in self.geocode_cache.items():
                serializable_cache[key] = {
                    'lat': geo.lat,
                    'lon': geo.lon,
                    'source': geo.source,
                    'confidence': geo.confidence
                }
            
            with open(cache_file, 'w') as f:
                json.dump(serializable_cache, f)
            logger.info(f"Saved {len(self.geocode_cache)} geocode results to cache")
        except Exception as e:
            logger.warning(f"Could not save geocode cache: {e}")
    
    def add_spatial_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add spatial clustering and density features"""
        
        # Calculate distances to major centers
        centers = {
            'downtown_kc': (39.0997, -94.5786),
            'overland_park': (38.9822, -94.6708),
            'kci_airport': (39.2973, -94.7139),
        }
        
        for center_name, (lat, lon) in centers.items():
            df[f'dist_to_{center_name}'] = self._haversine_distance(
                df['latitude'], df['longitude'], lat, lon
            )
        
        # Add density features (businesses per square mile in 5-mile radius)
        df['local_business_density'] = self._calculate_density(df)
        
        # Add spatial cluster ID
        df['spatial_cluster'] = self._identify_spatial_clusters(df)
        
        return df
    
    def _haversine_distance(self, lat1, lon1, lat2, lon2):
        """Calculate distance in miles between coordinates"""
        
        # Convert to numpy arrays and handle pandas Series
        if hasattr(lat1, 'values'):  # pandas Series
            lat1 = lat1.values
        if hasattr(lon1, 'values'):  # pandas Series
            lon1 = lon1.values
        if hasattr(lat2, 'values'):  # pandas Series
            lat2 = lat2.values
        if hasattr(lon2, 'values'):  # pandas Series
            lon2 = lon2.values
            
        lat1 = np.radians(np.array(lat1, dtype=float))
        lon1 = np.radians(np.array(lon1, dtype=float))
        lat2 = np.radians(np.array(lat2, dtype=float))
        lon2 = np.radians(np.array(lon2, dtype=float))
        
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        
        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
        c = 2 * np.arcsin(np.sqrt(a))
        
        # Radius of Earth in miles
        r = 3956
        
        return c * r
    
    def _calculate_density(self, df: pd.DataFrame, radius_miles: float = 5.0) -> pd.Series:
        """Calculate business density around each location"""
        density = []
        
        # Sample calculation for efficiency (full calculation would be O(nÂ²))
        sample_size = min(1000, len(df))
        sample_df = df.sample(n=sample_size, random_state=42) if len(df) > sample_size else df
        
        for idx, row in df.iterrows():
            # Count businesses within radius
            distances = self._haversine_distance(
                row['latitude'], row['longitude'],
                sample_df['latitude'].values, sample_df['longitude'].values
            )
            
            count_in_radius = (distances <= radius_miles).sum()
            # Normalize by sample ratio
            if len(df) > sample_size:
                count_in_radius = count_in_radius * (len(df) / sample_size)
            
            # Convert to density (businesses per square mile)
            area = np.pi * radius_miles ** 2
            density.append(count_in_radius / area)
        
        return pd.Series(density, index=df.index)
    
    def _identify_spatial_clusters(self, df: pd.DataFrame, n_clusters: int = 20) -> pd.Series:
        """Identify spatial business clusters using k-means"""
        from sklearn.cluster import KMeans
        
        # Use lat/lon for clustering
        coords = df[['latitude', 'longitude']].values
        
        # Perform k-means clustering
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(coords)
        
        return pd.Series(cluster_labels, index=df.index)
